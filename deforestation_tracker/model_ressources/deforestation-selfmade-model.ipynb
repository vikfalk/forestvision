{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8540604,"sourceType":"datasetVersion","datasetId":5102186},{"sourceId":8540627,"sourceType":"datasetVersion","datasetId":5102201},{"sourceId":8550025,"sourceType":"datasetVersion","datasetId":5109023},{"sourceId":8550080,"sourceType":"datasetVersion","datasetId":5109070},{"sourceId":8557369,"sourceType":"datasetVersion","datasetId":5114335},{"sourceId":8557375,"sourceType":"datasetVersion","datasetId":5114341}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install rasterio\n# !pip install focal_loss","metadata":{"id":"1yieC7Clp5st","outputId":"1651ea35-7c99-4820-897c-22e6adb4f484","execution":{"iopub.status.busy":"2024-05-29T07:46:14.239704Z","iopub.execute_input":"2024-05-29T07:46:14.240063Z","iopub.status.idle":"2024-05-29T07:46:48.831337Z","shell.execute_reply.started":"2024-05-29T07:46:14.240037Z","shell.execute_reply":"2024-05-29T07:46:48.830295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install pyyaml h5p","metadata":{"execution":{"iopub.status.busy":"2024-05-29T14:24:29.590261Z","iopub.execute_input":"2024-05-29T14:24:29.591211Z","iopub.status.idle":"2024-05-29T14:25:42.845393Z","shell.execute_reply.started":"2024-05-29T14:24:29.591176Z","shell.execute_reply":"2024-05-29T14:25:42.844132Z"},"id":"rsViwooRRbsJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport rasterio\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers, regularizers\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n#from focal_loss import BinaryFocalLoss\nimport tensorflow_hub as hub\nfrom PIL import Image\nfrom pathlib import Path\nimport keras_cv","metadata":{"id":"kNr9VGyscoQ8","execution":{"iopub.status.busy":"2024-05-30T13:45:32.717454Z","iopub.execute_input":"2024-05-30T13:45:32.717841Z","iopub.status.idle":"2024-05-30T13:45:32.724023Z","shell.execute_reply.started":"2024-05-30T13:45:32.717811Z","shell.execute_reply":"2024-05-30T13:45:32.723051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.executing_eagerly()","metadata":{"id":"j9agAAdFRbsP","outputId":"ca1047b3-0f09-4e24-f353-c79470de96f3","execution":{"iopub.status.busy":"2024-05-30T13:40:33.629006Z","iopub.execute_input":"2024-05-30T13:40:33.629517Z","iopub.status.idle":"2024-05-30T13:40:33.636225Z","shell.execute_reply.started":"2024-05-30T13:40:33.629492Z","shell.execute_reply":"2024-05-30T13:40:33.635237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"strategy = tf.distribute.MirroredStrategy()\nprint('DEVICES AVAILABLE: {}'.format(strategy.num_replicas_in_sync))","metadata":{"id":"SNqe0aApRbsj","outputId":"c12acc50-83c4-48c2-cf7f-170cde063bcb","execution":{"iopub.status.busy":"2024-05-30T13:40:33.637315Z","iopub.execute_input":"2024-05-30T13:40:33.637605Z","iopub.status.idle":"2024-05-30T13:40:34.545583Z","shell.execute_reply.started":"2024-05-30T13:40:33.637583Z","shell.execute_reply":"2024-05-30T13:40:34.544585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4-channel image analysis","metadata":{}},{"cell_type":"code","source":"def process_image(image_path):\n    image_path = image_path.numpy().decode('utf-8')\n    with rasterio.open(image_path) as src:\n        bands = [src.read(i) / src.read(i).max() for i in range(1, src.count + 1)]\n        img = np.stack(bands, axis=-1)\n    return img\n\ndef process_mask(mask_path):\n    mask_path = mask_path.numpy().decode('utf-8')\n    with rasterio.open(mask_path) as src:\n        mask = src.read(1)\n    return mask\n\ndef process_image_wrapper(image_path):\n    img = tf.py_function(process_image, [image_path], tf.float32)\n    img.set_shape([512, 512, 4])\n    img = tf.ensure_shape(img, [512, 512, 4])  # Ensure the shape is correct\n    return img\n\ndef process_mask_wrapper(mask_path):\n    mask = tf.py_function(process_mask, [mask_path], tf.float32)\n    mask = tf.expand_dims(mask, axis=-1)  # Add the channel dimension\n    mask.set_shape([512, 512, 1])\n    mask = tf.ensure_shape(mask, [512, 512, 1])  # Ensure the shape is correct\n    return mask","metadata":{"id":"qY1X_rRrRbsk","execution":{"iopub.status.busy":"2024-05-30T13:40:34.547634Z","iopub.execute_input":"2024-05-30T13:40:34.548072Z","iopub.status.idle":"2024-05-30T13:40:34.558930Z","shell.execute_reply.started":"2024-05-30T13:40:34.548043Z","shell.execute_reply":"2024-05-30T13:40:34.558006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.chdir('/kaggle/input')\n\nimage_dataset = None\nmask_dataset = None\nimage_val = None\nmask_val = None\n\ndata_dir = 'images'\nmask_dir = 'labels'\nval_images = 'images-val'\nval_masks = 'masks-val'\ntest_images = 'images-test'\ntest_masks = 'masks-test'\n\n# Dataset for images\nimage_dataset = tf.data.Dataset.list_files(f'{data_dir}/*.tif', shuffle=False)\nimage_dataset = image_dataset.map(process_image_wrapper)\n\n# Dataset for masks\nmask_dataset = tf.data.Dataset.list_files(f'{mask_dir}/*.tif', shuffle=False)\nmask_dataset = mask_dataset.map(process_mask_wrapper)\n\n# Validation dataset for images\nimage_val = tf.data.Dataset.list_files(f'{val_images}/*.tif', shuffle=False)\nimage_val = image_val.map(process_image_wrapper)\n\n# Validation dataset for masks\nmask_val = tf.data.Dataset.list_files(f'{val_masks}/*.tif', shuffle=False)\nmask_val = mask_val.map(process_mask_wrapper)\n\n# Test dataset for images\nimage_test = tf.data.Dataset.list_files(f'{test_images}/*.tif', shuffle=False)\nimage_test = image_test.map(process_image_wrapper)\n\n# Test dataset for masks\nmask_test = tf.data.Dataset.list_files(f'{test_masks}/*.tif', shuffle=False)\nmask_test = mask_test.map(process_mask_wrapper)","metadata":{"id":"JOubTlvxRbsk","execution":{"iopub.status.busy":"2024-05-30T13:40:34.560154Z","iopub.execute_input":"2024-05-30T13:40:34.560442Z","iopub.status.idle":"2024-05-30T13:40:35.397215Z","shell.execute_reply.started":"2024-05-30T13:40:34.560419Z","shell.execute_reply":"2024-05-30T13:40:35.396136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for ds in mask_dataset.take(1):\n#    print(ds)","metadata":{"id":"HhNjaZyXRbsl","execution":{"iopub.status.busy":"2024-05-30T13:40:35.398486Z","iopub.execute_input":"2024-05-30T13:40:35.398805Z","iopub.status.idle":"2024-05-30T13:40:35.403938Z","shell.execute_reply.started":"2024-05-30T13:40:35.398779Z","shell.execute_reply":"2024-05-30T13:40:35.402905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Training data\n# Combine the image and mask datasets\ndataset = tf.data.Dataset.zip((image_dataset, mask_dataset))\n\n# Batch and prefetch the dataset\ndataset = dataset.batch(1).prefetch(tf.data.AUTOTUNE)\n\n## Validation data\n# Combine the image and mask datasets\nval_data = tf.data.Dataset.zip((image_val, mask_val))\n\n# Batch and prefetch the dataset\nval_data = val_data.batch(1).prefetch(tf.data.AUTOTUNE)\n\n## Test data\n# Combine the image and mask datasets\ntest_data = tf.data.Dataset.zip((image_test, mask_test))\n\n# Batch and prefetch the dataset\ntest_data = test_data.batch(1).prefetch(tf.data.AUTOTUNE)","metadata":{"id":"FaPqmXn4Rbsm","execution":{"iopub.status.busy":"2024-05-30T13:40:35.405092Z","iopub.execute_input":"2024-05-30T13:40:35.405398Z","iopub.status.idle":"2024-05-30T13:40:35.431256Z","shell.execute_reply.started":"2024-05-30T13:40:35.405351Z","shell.execute_reply":"2024-05-30T13:40:35.430564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for img, mask in test_data.take(1):\n    print(img.shape, mask.shape)","metadata":{"id":"CMnMVK0wRbsm","outputId":"b0395a73-3e13-46f5-d986-60be4ca0fc47","execution":{"iopub.status.busy":"2024-05-30T13:40:35.432211Z","iopub.execute_input":"2024-05-30T13:40:35.432483Z","iopub.status.idle":"2024-05-30T13:40:35.809366Z","shell.execute_reply.started":"2024-05-30T13:40:35.432453Z","shell.execute_reply":"2024-05-30T13:40:35.808479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nUseful blocks to build Unet\n\nconv - BN - Activation - conv - BN - Activation - Dropout (if enabled)\n\n'''\n\n\ndef conv_block(x, filter_size, size, dropout, batch_norm=False):\n\n    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(x)\n    if batch_norm is True:\n        conv = layers.BatchNormalization(axis=3)(conv)\n    conv = layers.Activation(\"relu\")(conv)\n\n    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(conv)\n    if batch_norm is True:\n        conv = layers.BatchNormalization(axis=3)(conv)\n    conv = layers.Activation(\"relu\")(conv)\n\n    if dropout > 0:\n        conv = layers.Dropout(dropout)(conv)\n\n    return conv\n\n\ndef repeat_elem(tensor, rep):\n    # lambda function to repeat Repeats the elements of a tensor along an axis\n    #by a factor of rep.\n    # If tensor has shape (None, 256,256,3), lambda will return a tensor of shape\n    #(None, 256,256,6), if specified axis=3 and rep=2.\n\n     return layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),\n                          arguments={'repnum': rep})(tensor)\n\n\ndef res_conv_block(x, filter_size, size, dropout, batch_norm=False):\n    '''\n    Residual convolutional layer.\n    Two variants....\n    Either put activation function before the addition with shortcut\n    or after the addition (which would be as proposed in the original resNet).\n\n    1. conv - BN - Activation - conv - BN - Activation\n                                          - shortcut  - BN - shortcut+BN\n\n    2. conv - BN - Activation - conv - BN\n                                     - shortcut  - BN - shortcut+BN - Activation\n\n    Check fig 4 in https://arxiv.org/ftp/arxiv/papers/1802/1802.06955.pdf\n    '''\n\n    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same')(x)\n    if batch_norm is True:\n        conv = layers.BatchNormalization(axis=3)(conv)\n    conv = layers.Activation('relu')(conv)\n\n    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same')(conv)\n    if batch_norm is True:\n        conv = layers.BatchNormalization(axis=3)(conv)\n    #conv = layers.Activation('relu')(conv)    #Activation before addition with shortcut\n    if dropout > 0:\n        conv = layers.Dropout(dropout)(conv)\n\n    shortcut = layers.Conv2D(size, kernel_size=(1, 1), padding='same')(x)\n    if batch_norm is True:\n        shortcut = layers.BatchNormalization(axis=3)(shortcut)\n\n    res_path = layers.add([shortcut, conv])\n    res_path = layers.Activation('relu')(res_path)    #Activation after addition with shortcut (Original residual block)\n    return res_path\n\ndef gating_signal(input, out_size, batch_norm=False):\n    \"\"\"\n    resize the down layer feature map into the same dimension as the up layer feature map\n    using 1x1 conv\n    :return: the gating feature map with the same dimension of the up layer feature map\n    \"\"\"\n    x = layers.Conv2D(out_size, (1, 1), padding='same')(input)\n    if batch_norm:\n        x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    return x\n\ndef attention_block(x, gating, inter_shape):\n    shape_x = K.int_shape(x)\n    shape_g = K.int_shape(gating)\n\n# Getting the x signal to the same shape as the gating signal\n    theta_x = layers.Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same')(x)  # 16\n    shape_theta_x = K.int_shape(theta_x)\n\n# Getting the gating signal to the same number of filters as the inter_shape\n    phi_g = layers.Conv2D(inter_shape, (1, 1), padding='same')(gating)\n    upsample_g = layers.Conv2DTranspose(inter_shape, (3, 3),\n                                 strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),\n                                 padding='same')(phi_g)  # 16\n\n    concat_xg = layers.add([upsample_g, theta_x])\n    act_xg = layers.Activation('relu')(concat_xg)\n    psi = layers.Conv2D(1, (1, 1), padding='same')(act_xg)\n    sigmoid_xg = layers.Activation('sigmoid')(psi)\n    shape_sigmoid = K.int_shape(sigmoid_xg)\n    upsample_psi = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)  # 32\n\n    upsample_psi = repeat_elem(upsample_psi, shape_x[3])\n\n    y = layers.multiply([upsample_psi, x])\n\n    result = layers.Conv2D(shape_x[3], (1, 1), padding='same')(y)\n    result_bn = layers.BatchNormalization()(result)\n    return result_bn","metadata":{"id":"JpgEvNkWbbIS","execution":{"iopub.status.busy":"2024-05-30T14:17:38.110928Z","iopub.execute_input":"2024-05-30T14:17:38.111271Z","iopub.status.idle":"2024-05-30T14:17:38.132619Z","shell.execute_reply.started":"2024-05-30T14:17:38.111245Z","shell.execute_reply":"2024-05-30T14:17:38.131652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n\n\ndef jacard_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n\n\ndef jacard_coef_loss(y_true, y_pred):\n    return -jacard_coef(y_true, y_pred)\n\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)","metadata":{"id":"5Z9wbf_URbs7","execution":{"iopub.status.busy":"2024-05-30T14:17:39.091455Z","iopub.execute_input":"2024-05-30T14:17:39.091805Z","iopub.status.idle":"2024-05-30T14:17:39.099025Z","shell.execute_reply.started":"2024-05-30T14:17:39.091777Z","shell.execute_reply":"2024-05-30T14:17:39.098065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def UNet(input_shape, NUM_CLASSES=1, dropout_rate=0.0, batch_norm=True):\n    '''\n    UNet,\n\n    '''\n    # network structure\n    FILTER_NUM = 16 # number of filters for the first layer\n    FILTER_SIZE = 3 # size of the convolutional filter\n    UP_SAMP_SIZE = 2 # size of upsampling filters\n    \n    inputs = layers.Input(input_shape, dtype=tf.float32)\n    inputs = layers.RandomRotation(factor=0.5)(inputs)\n    inputs = layers.RandomFlip(mode=\"horizontal_and_vertical\")(inputs)\n\n    # Downsampling layers\n    # DownRes 1, convolution + pooling\n    conv_512 = conv_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n    pool_256 = layers.MaxPooling2D(pool_size=(2,2))(conv_512)\n    # DownRes 2\n    conv_256 = conv_block(pool_256, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n    pool_128 = layers.MaxPooling2D(pool_size=(2,2))(conv_256)\n    # DownRes 3\n    conv_128 = conv_block(pool_128, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n    pool_64 = layers.MaxPooling2D(pool_size=(2,2))(conv_128)\n    # DownRes 4\n    conv_64 = conv_block(pool_64, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n    #pool_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_64)\n    # DownRes 5, convolution only\n    #conv_32 = conv_block(pool_32, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n\n    # Upsampling layers\n\n    # up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(conv_32)\n    # up_64 = layers.concatenate([up_64, conv_64], axis=3)\n    # up_conv_64 = conv_block(up_64, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n    # UpRes 7\n\n    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(conv_64)\n    up_128 = layers.concatenate([up_128, conv_128], axis=3)\n    up_conv_128 = conv_block(up_128, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n    # UpRes 8\n\n    up_256 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_128)\n    up_256 = layers.concatenate([up_256, conv_256], axis=3)\n    up_conv_256 = conv_block(up_256, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n    # UpRes 9\n\n    up_512 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_256)\n    up_512 = layers.concatenate([up_512, conv_512], axis=3)\n    up_conv_512 = conv_block(up_512, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n\n    # 1*1 convolutional layers\n\n    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_512)\n    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n    conv_final = layers.Activation('sigmoid')(conv_final)\n\n    # Model\n    model = models.Model(inputs, conv_final, name=\"UNet\")\n    print(model.summary())\n    return model\n","metadata":{"id":"vDA2AB8YqffX","execution":{"iopub.status.busy":"2024-05-30T14:17:39.877053Z","iopub.execute_input":"2024-05-30T14:17:39.878025Z","iopub.status.idle":"2024-05-30T14:17:39.891839Z","shell.execute_reply.started":"2024-05-30T14:17:39.877989Z","shell.execute_reply":"2024-05-30T14:17:39.890881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unet = UNet(input_shape=(512,512,4), NUM_CLASSES=1, dropout_rate=0, batch_norm=True)","metadata":{"id":"1cfBzB16Rbs9","outputId":"2f06e408-7a25-4087-b8a6-b849fb2fcc88","execution":{"iopub.status.busy":"2024-05-30T14:17:41.093742Z","iopub.execute_input":"2024-05-30T14:17:41.094070Z","iopub.status.idle":"2024-05-30T14:17:41.459611Z","shell.execute_reply.started":"2024-05-30T14:17:41.094046Z","shell.execute_reply":"2024-05-30T14:17:41.458730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = Adam(learning_rate=0.0005)\nunet.compile(optimizer=optimizer, loss=dice_coef_loss, metrics=['accuracy'])","metadata":{"id":"gcKIigL_uwvm","execution":{"iopub.status.busy":"2024-05-30T14:17:43.078627Z","iopub.execute_input":"2024-05-30T14:17:43.079533Z","iopub.status.idle":"2024-05-30T14:17:43.088632Z","shell.execute_reply.started":"2024-05-30T14:17:43.079500Z","shell.execute_reply":"2024-05-30T14:17:43.087831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = EarlyStopping(patience=7, restore_best_weights=True)","metadata":{"id":"VwprNCiTvIpi","execution":{"iopub.status.busy":"2024-05-30T14:17:43.826857Z","iopub.execute_input":"2024-05-30T14:17:43.827201Z","iopub.status.idle":"2024-05-30T14:17:43.831958Z","shell.execute_reply.started":"2024-05-30T14:17:43.827176Z","shell.execute_reply":"2024-05-30T14:17:43.831014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#unet.fit(dataset, batch_size=32, epochs=6, validation_data=val_data)","metadata":{"id":"ppBI7ap9wGsO","outputId":"a4be3bf2-f13a-4092-e264-c6b3394fdc72","execution":{"iopub.status.busy":"2024-05-30T14:17:44.597802Z","iopub.execute_input":"2024-05-30T14:17:44.598520Z","iopub.status.idle":"2024-05-30T14:17:44.602182Z","shell.execute_reply.started":"2024-05-30T14:17:44.598484Z","shell.execute_reply":"2024-05-30T14:17:44.601293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Attention_UNet(input_shape, NUM_CLASSES=1, dropout_rate=0.0, batch_norm=True):\n    '''\n    Deep Attention UNet, \n    \n    '''\n    # network structure\n    FILTER_NUM = 16 # number of basic filters for the first layer\n    FILTER_SIZE = 3 # size of the convolutional filter\n    UP_SAMP_SIZE = 2 # size of upsampling filters\n    \n    inputs = layers.Input(input_shape, dtype=tf.float32)\n    inputs = layers.RandomRotation(factor=0.5)(inputs)\n    inputs = layers.RandomFlip(mode=\"horizontal_and_vertical\")(inputs)\n\n    # Downsampling layers\n    # DownRes 1, convolution + pooling\n    conv_512 = conv_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n    pool_256 = layers.MaxPooling2D(pool_size=(2,2))(conv_512)\n    # DownRes 2\n    conv_256 = conv_block(pool_256, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n    pool_128 = layers.MaxPooling2D(pool_size=(2,2))(conv_256)\n    # DownRes 3\n    conv_128 = conv_block(pool_128, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n    pool_64 = layers.MaxPooling2D(pool_size=(2,2))(conv_128)\n    # DownRes 4\n    conv_64 = conv_block(pool_64, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n    pool_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_64)\n    # DownRes 5, convolution only\n    conv_32 = conv_block(pool_32, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n\n    # Upsampling layers\n    # UpRes 6, attention gated concatenation + upsampling + double residual convolution\n    gating_64 = gating_signal(conv_32, 8*FILTER_NUM, batch_norm)\n    att_64 = attention_block(conv_64, gating_64, 8*FILTER_NUM)\n    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(conv_32)\n    up_64 = layers.concatenate([up_64, att_64], axis=3)\n    up_conv_64 = conv_block(up_64, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n    # UpRes 7\n    gating_128 = gating_signal(up_conv_64, 4*FILTER_NUM, batch_norm) # change to up_conv_64 with deeper structure \n    att_128 = attention_block(conv_128, gating_128, 4*FILTER_NUM)\n    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_64) # change to up_conv_64 with deeper structure \n    up_128 = layers.concatenate([up_128, att_128], axis=3)\n    up_conv_128 = conv_block(up_128, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n    # UpRes 8\n    gating_256 = gating_signal(up_conv_128, 2*FILTER_NUM, batch_norm)\n    att_256 = attention_block(conv_256, gating_256, 2*FILTER_NUM)\n    up_256 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_128)\n    up_256 = layers.concatenate([up_256, att_256], axis=3)\n    up_conv_256 = conv_block(up_256, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n    # UpRes 9\n    gating_512 = gating_signal(up_conv_256, FILTER_NUM, batch_norm)\n    att_512 = attention_block(conv_512, gating_512, FILTER_NUM)\n    up_512 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_256)\n    up_512 = layers.concatenate([up_512, att_512], axis=3)\n    up_conv_512 = conv_block(up_512, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n\n    # 1*1 convolutional layers\n    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_512)\n    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n    conv_final = layers.Activation('sigmoid')(conv_final)  \n\n    # Model integration\n    model = models.Model(inputs, conv_final, name=\"Attention_UNet\")\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:17:44.946346Z","iopub.execute_input":"2024-05-30T14:17:44.946635Z","iopub.status.idle":"2024-05-30T14:17:44.962477Z","shell.execute_reply.started":"2024-05-30T14:17:44.946612Z","shell.execute_reply":"2024-05-30T14:17:44.961440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"att_unet = Attention_UNet(input_shape=(512,512,4), NUM_CLASSES=1, dropout_rate=0, batch_norm=True)","metadata":{"id":"R1RnfApURbtG","execution":{"iopub.status.busy":"2024-05-30T14:22:06.665018Z","iopub.execute_input":"2024-05-30T14:22:06.667138Z","iopub.status.idle":"2024-05-30T14:22:07.277207Z","shell.execute_reply.started":"2024-05-30T14:22:06.667103Z","shell.execute_reply":"2024-05-30T14:22:07.276418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#att_unet.summary()","metadata":{"id":"RzgqSvi-RbtH","outputId":"c91db724-5585-4899-d622-983b87decb2a","execution":{"iopub.status.busy":"2024-05-30T14:22:09.220059Z","iopub.execute_input":"2024-05-30T14:22:09.220418Z","iopub.status.idle":"2024-05-30T14:22:09.226592Z","shell.execute_reply.started":"2024-05-30T14:22:09.220391Z","shell.execute_reply":"2024-05-30T14:22:09.225596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = Adam(learning_rate=0.0005)\natt_unet.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"id":"xwUJbcFYRbtH","execution":{"iopub.status.busy":"2024-05-30T14:27:40.299626Z","iopub.execute_input":"2024-05-30T14:27:40.300002Z","iopub.status.idle":"2024-05-30T14:27:40.311230Z","shell.execute_reply.started":"2024-05-30T14:27:40.299973Z","shell.execute_reply":"2024-05-30T14:27:40.309891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = EarlyStopping(patience=15, restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=5) # potentially, specify min_lr\nsave_model = ModelCheckpoint('/kaggle/working/unet-attention-4d.keras', monitor='val_accuracy',verbose=1, save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:27:41.502417Z","iopub.execute_input":"2024-05-30T14:27:41.502882Z","iopub.status.idle":"2024-05-30T14:27:41.508324Z","shell.execute_reply.started":"2024-05-30T14:27:41.502852Z","shell.execute_reply":"2024-05-30T14:27:41.507407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"att_unet.fit(dataset, epochs=60, steps_per_epoch=100, callbacks=[es, reduce_lr, save_model], validation_data=val_data, batch_size=1)","metadata":{"id":"zr8Yl8OcRbtI","outputId":"9cb717af-19d9-47fb-db2d-d00d5ff466d7","execution":{"iopub.status.busy":"2024-05-30T14:27:54.545357Z","iopub.execute_input":"2024-05-30T14:27:54.545715Z","iopub.status.idle":"2024-05-30T14:33:47.019106Z","shell.execute_reply.started":"2024-05-30T14:27:54.545687Z","shell.execute_reply":"2024-05-30T14:33:47.018173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save model to hdf5 file\natt_unet.save('/kaggle/working/att_unet.hdf5')\n\n# Save model training history\nnp.save('/kaggle/working/unet-attention-4d-history.npy', att_unet.history.history)","metadata":{"id":"d71jVNjoRbtJ","outputId":"9b084f7b-58c5-49a0-db1c-44b82555ef79","execution":{"iopub.status.busy":"2024-05-30T14:34:57.960612Z","iopub.execute_input":"2024-05-30T14:34:57.960969Z","iopub.status.idle":"2024-05-30T14:34:58.334721Z","shell.execute_reply.started":"2024-05-30T14:34:57.960942Z","shell.execute_reply":"2024-05-30T14:34:58.333918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.chdir(\"/kaggle/input/\")\nfolder_path = 'images-test'\ntiff_files = [file for file in os.listdir(folder_path) if file.endswith('.tif')]\n#View first image file\nfirst_tiff_file = os.path.join(folder_path, tiff_files[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:35:08.652594Z","iopub.execute_input":"2024-05-30T14:35:08.653556Z","iopub.status.idle":"2024-05-30T14:35:08.659449Z","shell.execute_reply.started":"2024-05-30T14:35:08.653513Z","shell.execute_reply":"2024-05-30T14:35:08.658353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.chdir(\"/kaggle/input/\")\nmask_path = 'masks-test'\ntiff_masks = [mask for mask in os.listdir(mask_path) if mask.endswith('.tif')]\n# View first mask\nfirst_mask = os.path.join(mask_path, tiff_masks[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:35:09.504832Z","iopub.execute_input":"2024-05-30T14:35:09.505171Z","iopub.status.idle":"2024-05-30T14:35:09.511498Z","shell.execute_reply.started":"2024-05-30T14:35:09.505146Z","shell.execute_reply":"2024-05-30T14:35:09.510376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_image_and_mask(image_path, mask_path):\n    # Open the image using wrapper function\n    test_image = process_image_wrapper(image_path)\n    test_image_exp = tf.expand_dims(test_image, axis=0)\n    test_pred = att_unet.predict(test_image_exp)\n    test_pred = test_pred.reshape((512,512,1))\n    \n    # Convert predicted image to black and white\n    threshold = 0.7\n    test_pred = (pred > threshold).astype(np.uint8) * 255\n    \n    # Open the mask using wrapper function\n    test_mask = process_mask_wrapper(mask_path)\n    \n    # Create subplots with 1 row and 2 columns\n    fig, axes = plt.subplots(1, 3, figsize=(12, 6))\n    # Display the RGB image in the first subplot\n    axes[0].imshow(test_image[:,:,:3])\n    axes[0].set_title('RGB Image')\n    axes[0].axis('off')\n    \n    axes[1].imshow(test_pred, cmap='gray')\n    axes[1].set_title('Prediction')\n    axes[1].axis('off')\n    # Display the mask in the second subplot\n\n    axes[2].imshow(test_mask, cmap='gray')\n    axes[2].set_title('Mask')\n    axes[2].axis('off')\n    # Adjust layout to prevent overlap\n    plt.tight_layout()\n    # Show the plot\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:35:26.604270Z","iopub.execute_input":"2024-05-30T14:35:26.605122Z","iopub.status.idle":"2024-05-30T14:35:26.614083Z","shell.execute_reply.started":"2024-05-30T14:35:26.605089Z","shell.execute_reply":"2024-05-30T14:35:26.613068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_image_and_mask(first_tiff_file, first_mask)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:35:27.206563Z","iopub.execute_input":"2024-05-30T14:35:27.207410Z","iopub.status.idle":"2024-05-30T14:35:27.801687Z","shell.execute_reply.started":"2024-05-30T14:35:27.207377Z","shell.execute_reply":"2024-05-30T14:35:27.800896Z"},"trusted":true},"execution_count":null,"outputs":[]}]}